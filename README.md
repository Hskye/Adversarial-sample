# Adversarial-sample
some resources arrangement

#### Competition
Face Recognition:
[MCS 2018. Adversarial Attacks on Black Box Face Recognition](https://competitions.codalab.org/competitions/19090#participate)

比赛的目标是欺骗BB模型使其不能正确的分类两张完全不同的人脸图像（按照L2正则化），此比赛为黑盒攻击；
实现攻击最简单的方式是清楚模型的结构（有人建议...对BB的推理时间进行计时，从而推断出它的架构）

- the winners' presentations: [MCS2018.pdf](https://drive.google.com/file/d/1P-4AdCqw81nOK79vU_m7IsCVzogdeSNq/view)
  
  https://spark-in.me/post/playing-with-mcs2018-adversarial-attacks
- All winners' presentations: MCS_comp_final.pdf
- Some solution
  https://github.com/snakers4/msc-2018-final （1st）
  
  https://github.com/Atmyre/MCS2018_Solution (2nd)
  
  https://github.com/mortido
  
  https://github.com/snakers4
  
  https://github.com/stalkermustang


[ImageNet](http://image-net.org/synset?wnid=n02084071): [NIPS 2017: Non-targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack)
[]()

#### Github
baseline:
https://github.com/AlexanderParkin/MCS2018.Baseline

some result:
https://github.com/snakers4/msc-2018-final

#### reference
momentum: http://ruder.io/optimizing-gradient-descent/index.html#momentum
